{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Load up the word vector and raw FDA approved drug names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "# load the word embedding model\n",
    "wv = KeyedVectors.load_word2vec_format('bio_embedding_intrinsic', binary=True)\n",
    "# and our approved drug names\n",
    "drugs = None\n",
    "with open('fda_approved/fda_approved.processed.names') as infile:\n",
    "    drugs = [l.strip() for l in infile]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Raw FDA Approved Drug Names to Vectors\n",
    "Here we take the FDA approved drug names and convert them to word vectors.\n",
    "First, we break them into tokens.\n",
    "Then, for each drug, we get word vectors for each individual token and average them for the drug.\n",
    "We drop individual tokens that are not in the vocab, modifying the drug name along with the average.\n",
    "Obviously, drug names with no tokens in the vocab are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're first going to convert every multi-token drug into a word vector average\n",
    "def wv_avg_tokens(tokens, wv):\n",
    "    # collect the unit vectors for each token\n",
    "    new_toks = list()\n",
    "    unit_vecs = list()\n",
    "    for t in tokens:\n",
    "        # skip tokens that aren't in the embedding\n",
    "        if t in wv:\n",
    "            # keep the token\n",
    "            new_toks.append(t)\n",
    "            # scale to a unit vector\n",
    "            uvec = wv[t]\n",
    "            uvec = uvec / np.linalg.norm(uvec)\n",
    "            unit_vecs.append(uvec)\n",
    "    # now add them up if we got at least one\n",
    "    if len(unit_vecs) < 1:\n",
    "        return None,None\n",
    "    # sum\n",
    "    ret_vec = unit_vecs[0]\n",
    "    for uvec in unit_vecs[1:]:\n",
    "        ret_vec = ret_vec + uvec\n",
    "    # and rescale\n",
    "    ret_vec = ret_vec / np.linalg.norm(ret_vec)\n",
    "    return new_toks,ret_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting drug count: 8561\n",
      "Converted drug count: 6506\n",
      "Final distinct drug vector count: 5850\n"
     ]
    }
   ],
   "source": [
    "# how many raw drugs are we starting with again?\n",
    "print('Starting drug count: {0}'.format(len(drugs)))\n",
    "# gather up our drug vectors with the corresponding \"new\" names (based on token dropping)\n",
    "drug_vec_tups = list()\n",
    "# and track the drugs that were dropped completely\n",
    "dropped_drugs = list()\n",
    "for d in drugs:\n",
    "    # split and average word vectors\n",
    "    toks = d.split()\n",
    "    new_toks,drug_vec = wv_avg_tokens(toks, wv)\n",
    "    # check for complete loss of a drug, or track the new name and vector\n",
    "    if drug_vec is None:\n",
    "        dropped_drugs.append(d)\n",
    "    else:\n",
    "        new_name = ' '.join(new_toks)\n",
    "        drug_vec_tups.append((new_name, drug_vec))\n",
    "# and how many raw drug names were we able to convert into something\n",
    "print('Converted drug count: {0}'.format(len(drug_vec_tups)))\n",
    "# because we have modified drug names, we may have ended up with new dupes\n",
    "tmp = list()\n",
    "drug_seen = set()\n",
    "for dvt in drug_vec_tups:\n",
    "    if dvt[0] not in drug_seen:\n",
    "        tmp.append(dvt)\n",
    "        drug_seen.add(dvt[0])\n",
    "drug_vec_tups = tmp\n",
    "# and how many distinct converted drug names do we have\n",
    "print('Final distinct drug vector count: {0}'.format(len(drug_vec_tups)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Treatment Analogy Vectors\n",
    "Now we generate treatment analogy vectors.\n",
    "We use three analogies: Metformin-Diabetes, Benazepril-Hypertension, and Albuterol-Asthma.\n",
    "These are the vectors we will use to rank the drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sars_treatment_analogy(seed_drug, seed_disease, wv):\n",
    "    drug_v = wv[seed_drug] / np.linalg.norm(wv[seed_drug])\n",
    "    dis_v = wv[seed_disease] / np.linalg.norm(wv[seed_disease])\n",
    "    sars_v = wv['sars'] / np.linalg.norm(wv['sars'])\n",
    "    treat_sars_vec = drug_v - dis_v + sars_v\n",
    "    treat_sars_vec = treat_sars_vec / np.linalg.norm(treat_sars_vec)\n",
    "    return treat_sars_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metf_diab_sars_v = get_sars_treatment_analogy('metformin', 'diabetes', wv)\n",
    "benz_hypr_sars_v = get_sars_treatment_analogy('benazepril', 'hypertension', wv)\n",
    "albu_asth_sars_v = get_sars_treatment_analogy('albuterol', 'asthma', wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Top 20 Hits for Treatment Vectors\n",
    "We want to manually evaluate the top 20 hits for each treatment analogy to check for drugs and drug targets.\n",
    "Finding drugs and drug targets in the top hits would suggest that the treatment vectors are in the right neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metf_diab_sars_top20 = wv.most_similar(positive=[metf_diab_sars_v], topn=20)\n",
    "benz_hypr_sars_top20 = wv.most_similar(positive=[benz_hypr_sars_v], topn=20)\n",
    "albu_asth_sars_top20 = wv.most_similar(positive=[albu_asth_sars_v], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metformin/Diabetes Top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sars', 0.7350299954414368)\n",
      "('sars-cov', 0.5995138883590698)\n",
      "('sars-3cl', 0.5938767194747925)\n",
      "('sars-3clpro', 0.5917655825614929)\n",
      "('sars-like', 0.588849663734436)\n",
      "('sars-covs', 0.5769191980361938)\n",
      "('sars-cov-induced', 0.5742613077163696)\n",
      "('sars-cov-mediated', 0.5720081925392151)\n",
      "('sars-cov-like', 0.5706111788749695)\n",
      "('anti-sars-cov', 0.5702001452445984)\n",
      "('pcsars-cov', 0.5684103965759277)\n",
      "('hsars-cov', 0.5669524669647217)\n",
      "('sars-co', 0.5651364922523499)\n",
      "('anticoronaviral', 0.561847984790802)\n",
      "('cantharimide', 0.5608478784561157)\n",
      "('sar405', 0.5591368675231934)\n",
      "('peramivir', 0.5569697618484497)\n",
      "('norcantharidin-induced', 0.5555316209793091)\n",
      "('cantharidin-mediated', 0.555138111114502)\n",
      "('delaviridine', 0.5549775958061218)\n"
     ]
    }
   ],
   "source": [
    "# just have a quick look at the hits and similarities\n",
    "print('\\n'.join([str(h) for h in metf_diab_sars_top20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sars \\\\\n",
      "sars-cov \\\\\n",
      "sars-3cl \\\\\n",
      "sars-3clpro \\\\\n",
      "sars-like \\\\\n",
      "sars-covs \\\\\n",
      "sars-cov-induced \\\\\n",
      "sars-cov-mediated \\\\\n",
      "sars-cov-like \\\\\n",
      "anti-sars-cov \\\\\n",
      "pcsars-cov \\\\\n",
      "hsars-cov \\\\\n",
      "sars-co \\\\\n",
      "anticoronaviral \\\\\n",
      "cantharimide \\\\\n",
      "sar405 \\\\\n",
      "peramivir \\\\\n",
      "norcantharidin-induced \\\\\n",
      "cantharidin-mediated \\\\\n",
      "delaviridine \\\\\n"
     ]
    }
   ],
   "source": [
    "# and clean them up for a LaTeX table\n",
    "print('\\n'.join(['{0} \\\\\\\\'.format(h[0]) for h in metf_diab_sars_top20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benazepril/Hypertension Top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sars', 0.6842663288116455)\n",
      "('sars-3cl', 0.6048033237457275)\n",
      "('sars-3clpro', 0.5865695476531982)\n",
      "('sars-', 0.5783016085624695)\n",
      "('sars-cov', 0.5710662007331848)\n",
      "('sars-covs', 0.5611740946769714)\n",
      "('p-sars', 0.5571820735931396)\n",
      "('sars-like', 0.5532996654510498)\n",
      "('sarsp', 0.5501185655593872)\n",
      "('sars-cov-like', 0.5482956171035767)\n",
      "('sars-hcov', 0.5416980981826782)\n",
      "('anti-sars-cov', 0.5390284061431885)\n",
      "('sars-s', 0.5341991186141968)\n",
      "('coronavirion', 0.5340977907180786)\n",
      "('lycodine', 0.5312058925628662)\n",
      "('sarspp', 0.5307182669639587)\n",
      "('sarse', 0.5294245481491089)\n",
      "('sars-cov-s', 0.5278017520904541)\n",
      "('sars-cov-', 0.5276678204536438)\n",
      "('pcsars-cov', 0.5257420539855957)\n"
     ]
    }
   ],
   "source": [
    "# just have a quick look at the hits and similarities\n",
    "print('\\n'.join([str(h) for h in benz_hypr_sars_top20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sars \\\\\n",
      "sars-3cl \\\\\n",
      "sars-3clpro \\\\\n",
      "sars- \\\\\n",
      "sars-cov \\\\\n",
      "sars-covs \\\\\n",
      "p-sars \\\\\n",
      "sars-like \\\\\n",
      "sarsp \\\\\n",
      "sars-cov-like \\\\\n",
      "sars-hcov \\\\\n",
      "anti-sars-cov \\\\\n",
      "sars-s \\\\\n",
      "coronavirion \\\\\n",
      "lycodine \\\\\n",
      "sarspp \\\\\n",
      "sarse \\\\\n",
      "sars-cov-s \\\\\n",
      "sars-cov- \\\\\n",
      "pcsars-cov \\\\\n"
     ]
    }
   ],
   "source": [
    "# and clean them up for a LaTeX table\n",
    "print('\\n'.join(['{0} \\\\\\\\'.format(h[0]) for h in benz_hypr_sars_top20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Albuterol/Asthma Top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sars', 0.7238022685050964)\n",
      "('sars-cov', 0.5882976055145264)\n",
      "('csars', 0.5856403112411499)\n",
      "('sars-covs', 0.5827745199203491)\n",
      "('sarspp', 0.5768842101097107)\n",
      "('sars-like', 0.5768049359321594)\n",
      "('sars-cov-like', 0.5722691416740417)\n",
      "('peramivir', 0.5660814046859741)\n",
      "('vero-pipecuronium', 0.5657573938369751)\n",
      "('sarsp', 0.5637783408164978)\n",
      "('pancuronium-metocurine', 0.559868335723877)\n",
      "('sars-hcov', 0.5589520931243896)\n",
      "('sarse', 0.5587899684906006)\n",
      "('pcsars-cov', 0.5573618412017822)\n",
      "('sars-3cl', 0.5541790723800659)\n",
      "('p-sars', 0.5507079362869263)\n",
      "('sars-3clpro', 0.548815131187439)\n",
      "('sars-', 0.5467952489852905)\n",
      "('sars-coronavirus', 0.5443072319030762)\n",
      "('pralidoxime', 0.5440007448196411)\n"
     ]
    }
   ],
   "source": [
    "# just have a quick look at the hits and similarities\n",
    "print('\\n'.join([str(h) for h in albu_asth_sars_top20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sars \\\\\n",
      "sars-cov \\\\\n",
      "csars \\\\\n",
      "sars-covs \\\\\n",
      "sarspp \\\\\n",
      "sars-like \\\\\n",
      "sars-cov-like \\\\\n",
      "peramivir \\\\\n",
      "vero-pipecuronium \\\\\n",
      "sarsp \\\\\n",
      "pancuronium-metocurine \\\\\n",
      "sars-hcov \\\\\n",
      "sarse \\\\\n",
      "pcsars-cov \\\\\n",
      "sars-3cl \\\\\n",
      "p-sars \\\\\n",
      "sars-3clpro \\\\\n",
      "sars- \\\\\n",
      "sars-coronavirus \\\\\n",
      "pralidoxime \\\\\n"
     ]
    }
   ],
   "source": [
    "# and clean them up for a LaTeX table\n",
    "print('\\n'.join(['{0} \\\\\\\\'.format(h[0]) for h in albu_asth_sars_top20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Top 50 FDA Approved Drugs for Treatment Vectors\n",
    "We now sort all of the FDA approved drug vectors by their cosine similarity to the analogy vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_drugs_for_treat_vec(treat_vector, drug_vec_tups, wv):\n",
    "    # first get the similarities for all drugs\n",
    "    dvs = [dt[1] for dt in drug_vec_tups]\n",
    "    drug_treat_sims = wv.cosine_similarities(treat_vector, dvs)\n",
    "    # then zip them up with the drug names\n",
    "    drug_sim_tups = [(dvt[0],drug_treat_sims[i]) for i,dvt in enumerate(drug_vec_tups)]\n",
    "    # and sort, descending\n",
    "    return sorted(drug_sim_tups, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "metf_diab_drugs_top50 = get_ranked_drugs_for_treat_vec(metf_diab_sars_v, drug_vec_tups, wv)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gilteritinib fumarate', 0.5596477)\n",
      "('peramivir', 0.5569698)\n",
      "('zanamivir', 0.547)\n",
      "('erdafitinib', 0.5287651)\n",
      "('atovaquone and proguanil hydrochloride', 0.52664137)\n",
      "('rimantadine hydrochloride', 0.52499855)\n",
      "('delavirdine mesylate', 0.52425665)\n",
      "('atazanavir sulfate and ritonavir', 0.52155674)\n",
      "('cobimetinib fumarate', 0.520225)\n",
      "('niclosamide', 0.5195863)\n",
      "('lopinavir and ritonavir', 0.5190796)\n",
      "('temsirolimus', 0.5146165)\n",
      "('rilpivirine hydrochloride', 0.5108443)\n",
      "('alectinib hydrochloride', 0.5094977)\n",
      "('lefamulin acetate', 0.5077357)\n",
      "('perphenazine and amitriptyline hydrochloride', 0.50719637)\n",
      "('alogliptin and metformin hydrochloride', 0.506837)\n",
      "('tamiflu', 0.506541)\n",
      "('selinexor', 0.50538564)\n",
      "('amprenavir', 0.5043439)\n",
      "('ibuprofen and diphenhydramine citrate', 0.5035539)\n",
      "('olanzapine and fluoxetine hydrochloride', 0.50291455)\n",
      "('probenecid and colchicine', 0.50227225)\n",
      "('erlotinib hydrochloride', 0.5016404)\n",
      "('bicalutamide', 0.50161445)\n",
      "('alomide', 0.5014721)\n",
      "('amantadine hydrochloride', 0.50131154)\n",
      "('azelastine hydrochloride and fluticasone propionate', 0.500887)\n",
      "('revefenacin', 0.5004103)\n",
      "('imipramine pamoate', 0.50003874)\n",
      "('doravirine', 0.50002295)\n",
      "('rosiglitazone maleate and metformin hydrochloride', 0.49872023)\n",
      "('nefazodone hydrochloride', 0.49831778)\n",
      "('mefloquine hydrochloride', 0.49804163)\n",
      "('abacavir sulfate and lamivudine', 0.49790433)\n",
      "('carisoprodol compound', 0.49745348)\n",
      "('triprolidine and pseudoephedrine hydrochlorides codeine', 0.49703676)\n",
      "('soma compound codeine', 0.49700755)\n",
      "('chloroquine hydrochloride', 0.4960756)\n",
      "('saquinavir mesylate', 0.4955613)\n",
      "('linagliptin and metformin hydrochloride', 0.49545392)\n",
      "('nilutamide', 0.49470964)\n",
      "('donepezil hydrochloride and memantine hydrochloride', 0.49466506)\n",
      "('memantine hydrochloride and donepezil hydrochloride', 0.49466506)\n",
      "('nelfinavir mesylate', 0.49460113)\n",
      "('ceritinib', 0.49452418)\n",
      "('virazole', 0.49377733)\n",
      "('vorinostat', 0.493377)\n",
      "('triprolidine and pseudoephedrine hydrochlorides', 0.4931573)\n",
      "('fulvestrant', 0.4924318)\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([str(x) for x in metf_diab_drugs_top50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
