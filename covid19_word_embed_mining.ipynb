{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Load up the word vector and raw FDA approved drug names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "# load the word embedding model\n",
    "wv = KeyedVectors.load_word2vec_format('bio_embedding_intrinsic', binary=True)\n",
    "# and our approved drug names\n",
    "drugs = None\n",
    "with open('fda_approved/fda_approved.processed.names') as infile:\n",
    "    drugs = [l.strip() for l in infile]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Raw FDA Approved Drug Names to Vectors\n",
    "Here we take the FDA approved drug names and convert them to word vectors.\n",
    "First, we break them into tokens.\n",
    "Then, for each drug, we get word vectors for each individual token and average them for the drug.\n",
    "We drop individual tokens that are not in the vocab, modifying the drug name along with the average.\n",
    "Obviously, drug names with no tokens in the vocab are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're first going to convert every multi-token drug into a word vector average\n",
    "def wv_avg_tokens(tokens, wv):\n",
    "    # collect the unit vectors for each token\n",
    "    new_toks = list()\n",
    "    unit_vecs = list()\n",
    "    for t in tokens:\n",
    "        # skip tokens that aren't in the embedding\n",
    "        if t in wv:\n",
    "            # keep the token\n",
    "            new_toks.append(t)\n",
    "            # scale to a unit vector\n",
    "            uvec = wv[t]\n",
    "            uvec = uvec / np.linalg.norm(uvec)\n",
    "            unit_vecs.append(uvec)\n",
    "    # now add them up if we got at least one\n",
    "    if len(unit_vecs) < 1:\n",
    "        return None,None\n",
    "    # sum\n",
    "    ret_vec = unit_vecs[0]\n",
    "    for uvec in unit_vecs[1:]:\n",
    "        ret_vec = ret_vec + uvec\n",
    "    # and rescale\n",
    "    ret_vec = ret_vec / np.linalg.norm(ret_vec)\n",
    "    return new_toks,ret_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting drug count: 8561\n",
      "Converted drug count: 6506\n",
      "Final distinct drug vector count: 5850\n"
     ]
    }
   ],
   "source": [
    "# how many raw drugs are we starting with again?\n",
    "print('Starting drug count: {0}'.format(len(drugs)))\n",
    "# gather up our drug vectors with the corresponding \"new\" names (based on token dropping)\n",
    "drug_vec_tups = list()\n",
    "# and track the drugs that were dropped completely\n",
    "dropped_drugs = list()\n",
    "for d in drugs:\n",
    "    # split and average word vectors\n",
    "    toks = d.split()\n",
    "    new_toks,drug_vec = wv_avg_tokens(toks, wv)\n",
    "    # check for complete loss of a drug, or track the new name and vector\n",
    "    if drug_vec is None:\n",
    "        dropped_drugs.append(d)\n",
    "    else:\n",
    "        new_name = ' '.join(new_toks)\n",
    "        drug_vec_tups.append((new_name, drug_vec))\n",
    "# and how many raw drug names were we able to convert into something\n",
    "print('Converted drug count: {0}'.format(len(drug_vec_tups)))\n",
    "# because we have modified drug names, we may have ended up with new dupes\n",
    "tmp = list()\n",
    "drug_seen = set()\n",
    "for dvt in drug_vec_tups:\n",
    "    if dvt[0] not in drug_seen:\n",
    "        tmp.append(dvt)\n",
    "        drug_seen.add(dvt[0])\n",
    "drug_vec_tups = tmp\n",
    "# and how many distinct converted drug names do we have\n",
    "print('Final distinct drug vector count: {0}'.format(len(drug_vec_tups)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
